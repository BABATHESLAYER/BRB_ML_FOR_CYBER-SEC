# This is the main entry point for the Flask web application.
# It provides a simple web interface to display the threat intelligence report
# generated by the autoti pipeline.

from flask import Flask, render_template_string
import sys
import os

# --- PATH CONFIGURATION ---
# This ensures that the 'autoti' package can be imported correctly.
# When the app is run, Python needs to know where to find the 'autoti' directory.
# We add the project's root directory to the Python path.
# This is crucial for the application to function when deployed.
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))


# --- DYNAMIC PIPELINE IMPORT ---
# We try to import the main 'run_pipeline' function from the autoti package.
# If there's an ImportError (e.g., due to missing dependencies or misconfiguration),
# we catch it and define a dummy 'run_pipeline' function.
# This allows the Flask app to still run and display a useful error message
# instead of crashing completely.
IMPORT_ERROR_MESSAGE = None
try:
    from autoti.analysis.langchain_agent import run_pipeline
except ImportError as e:
    IMPORT_ERROR_MESSAGE = str(e)
    print(f"FATAL ERROR: Could not import run_pipeline. Error: {IMPORT_ERROR_MESSAGE}")

    def run_pipeline():
        """A dummy function that returns an error message if the import fails."""
        return f"Application initialization failed. Import error: {IMPORT_ERROR_MESSAGE}"

# Initialize the Flask application.
app = Flask(__name__)


# --- HTML TEMPLATE ---
# A simple, self-contained HTML template for displaying the report.
# Using a multiline string here avoids the need for separate template files,
# making the application easy to manage as a single file.
REPORT_TEMPLATE = """
<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Threat Intelligence Report</title>
    <style>
        /* Basic styling for a clean, modern look. */
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f0f4f8;
            color: #1f2937;
        }
        .container {
            max-width: 1000px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 30px;
            border-radius: 12px;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        h1 {
            color: #111827;
            font-size: 2.25rem;
            border-bottom: 2px solid #e5e7eb;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        pre {
            background-color: #1f2937;
            color: #d1d5db;
            padding: 20px;
            border-radius: 8px;
            white-space: pre-wrap;
            word-wrap: break-word;
            line-height: 1.6;
        }
        .error {
            color: #b91c1c;
            background-color: #fee2e2;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #fca5a5;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Automated Threat Intelligence Executive Summary</h1>
        <p>Report generated on demand using OTX data and Gemini LLM analysis.</p>
        <!-- The 'report_content' will be replaced by the output of the pipeline. -->
        <pre>{{ report_content }}</pre>
    </div>
</body>
</html>
"""

# --- FLASK ROUTE ---
@app.route('/')
def report():
    """
    The main route for the web application.
    When a user visits the root URL, this function is called.
    It runs the full threat intelligence pipeline and displays the result.
    """
    try:
        # Execute the main pipeline function to get the report text.
        print("Starting pipeline for web request...")
        report_text = run_pipeline()
    except Exception as e:
        # If any other unexpected error occurs during the pipeline execution,
        # format it into an error message to be displayed on the web page.
        report_text = f"<div class='error'><strong>Report Generation Error!</strong><br>The pipeline failed to execute.<br>Error: {e}</div>"
        print(f"Flask App Error: {e}")

    # Render the HTML template, passing the generated report content to it.
    return render_template_string(REPORT_TEMPLATE, report_content=report_text)


# --- LOCAL DEVELOPMENT SERVER ---
if __name__ == '__main__':
    # This block allows the Flask app to be run directly for local testing
    # (e.g., by running 'python app.py').
    # In a production environment (like Docker), a proper WSGI server like Gunicorn
    # will be used to run the app, so this part won't be executed.
    app.run(host='0.0.0.0', port=5000)

# This script is the core of the automated threat intelligence pipeline.
# It uses the LangChain library to interact with a Large Language Model (LLM)
# from Google (Gemini) to generate a human-readable threat report.

import os
import pandas as pd
from dotenv import load_dotenv
from langchain_core.prompts import PromptTemplate
from langchain_classic.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI

# Load environment variables (like API keys) from a '.env' file.
# This is a secure way to manage sensitive information.
load_dotenv()

# --- PACKAGE IMPORTS ---
# Import the necessary functions from other parts of the 'autoti' package.
# 'get_latest_pulses' is used for data collection.
# 'normalize_pulses' is used for data processing.
from autoti.collection.otx_collector import get_latest_pulses
from autoti.processing.data_normalizer import normalize_pulses


# --- LLM AND API CONFIGURATION ---
# Retrieve the Google API key from environment variables.
# Using .get() provides a default value, which helps prevent errors if the key isn't set.
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY", "YOUR_API_KEY_HERE")


def get_llm(api_key):
    """
    Initializes and configures the Large Language Model (LLM).

    Args:
        api_key (str): The Google API key for authentication.

    Returns:
        ChatGoogleGenerativeAI: An instance of the LLM, ready to be used.
                                Returns None if the API key is missing.
    """
    if api_key in ("YOUR_API_KEY_HERE", None):
        print("ERROR: Google API Key is missing.")
        return None

    # We use Google's 'gemini-2.5-flash' model, which is fast and suitable for summaries.
    # 'temperature=0.2' makes the output more deterministic and focused.
    return ChatGoogleGenerativeAI(
        google_api_key=api_key,
        model="gemini-2.5-flash",
        temperature=0.2,
        convert_system_message_to_human=True
    )

def generate_threat_report(normalized_data, llm):
    """
    Generates the threat intelligence report by sending data and a prompt to the LLM.

    Args:
        normalized_data (pd.DataFrame): A DataFrame of processed threat data.
        llm (ChatGoogleGenerativeAI): The initialized LLM instance.

    Returns:
        str: The generated report text. Returns an error message on failure.
    """
    if llm is None:
        return "Report generation failed due to missing LLM configuration."

    if not isinstance(normalized_data, pd.DataFrame) or normalized_data.empty:
        return "No threat data available to generate a report."

    # --- DATA PREPARATION FOR LLM ---
    # We select the top 5 threats to create a concise summary.
    # The DataFrame is converted to a string, which is a format the LLM can easily understand.
    top_threats = normalized_data.head(5)
    data_summary_str = top_threats.to_string(
        columns=['threat_name', 'threat_description', 'ioc_count'],
        index=False
    )

    # --- PROMPT ENGINEERING ---
    # This is the instruction we give to the LLM. A well-crafted prompt is crucial
    # for getting a high-quality response.
    # We tell the LLM its role ('senior threat intelligence analyst'), the desired format,
    # and provide it with the data summary.
    prompt_template = """
    You are a senior threat intelligence analyst. Your task is to generate a concise, one-page executive summary report
    based on the threat intelligence data collected in the last 24 hours.

    The report must be structured as follows:
    1.  **Key Findings**: A high-level summary of the most significant threats.
    2.  **Top Threats Details**: A brief description of each of the top threats observed.
    3.  **General Mitigation Recommendations**: Actionable advice for a general audience to protect against these threats.

    Here is the summary of the threat data:
    ---
    {data_summary}
    ---

    Please generate the report now.
    """

    # We use LangChain's PromptTemplate to structure the prompt and define input variables.
    prompt = PromptTemplate(input_variables=["data_summary"], template=prompt_template)

    # An LLMChain combines the prompt and the LLM, creating a runnable component.
    chain = LLMChain(llm=llm, prompt=prompt)

    try:
        # We 'invoke' the chain, passing our data summary. This sends the request to the LLM.
        report = chain.invoke({"data_summary": data_summary_str})
        # The actual text is in the 'text' key of the response.
        return report['text']
    except Exception as e:
        # Handle potential errors during the API call.
        return f"Failed to generate report. Error: {e}"


# --- MAIN PIPELINE FUNCTION ---
def run_pipeline():
    """
    Orchestrates the entire process: data collection, processing, and report generation.
    This function is designed to be called by other parts of the application, like the Flask app.
    """
    print("--- Starting Automated Threat Intelligence Pipeline ---")

    # Retrieve the OTX API key from environment variables.
    otx_key = os.environ.get("OTX_API_KEY")

    # 1. Collect Data
    print("\nStep 1: Fetching latest threat intelligence data...")
    raw_pulses = get_latest_pulses(otx_key)

    # 2. Process Data
    print("\nStep 2: Normalizing raw data...")
    normalized_data = normalize_pulses(raw_pulses)

    # 3. Analyze and Generate Report
    print("\nStep 3: Initializing LLM and generating report...")
    llm = get_llm(GOOGLE_API_KEY)
    final_report = generate_threat_report(normalized_data, llm)

    print("\n--- Pipeline Finished ---")
    return final_report# This script is responsible for collecting threat intelligence data from AlienVault OTX (Open Threat Exchange).
# It fetches recent 'pulses', which are collections of threat indicators.

import os
import requests
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Load environment variables from a '.env' file for secure handling of API keys.
load_dotenv()

# --- API CONFIGURATION ---
# Retrieve the OTX API key from environment variables.
# Using .get() provides a default value to avoid errors if the key is not set.
OTX_API_KEY = os.environ.get("OTX_API_KEY", "YOUR_API_KEY_HERE")
# The base URL for the AlienVault OTX API.
BASE_URL = "https://otx.alienvault.com/api/v1"


def get_latest_pulses(api_key):
    """
    Fetches the latest threat intelligence pulses from AlienVault OTX from the last 24 hours.

    Args:
        api_key (str): Your AlienVault OTX API key.

    Returns:
        list: A list of dictionaries, where each dictionary is a threat pulse.
              Returns an empty list if the request fails.
    """
    if api_key in ("YOUR_API_KEY_HERE", None):
        print("ERROR: OTX API Key is missing. Please set it in your .env file.")
        return []

    # The API requires the key to be sent in the request headers.
    headers = {
        "X-OTX-API-KEY": api_key
    }

    # To get the most recent data, we calculate the timestamp for 24 hours ago.
    # The API will return pulses modified since this time.
    since_timestamp = (datetime.now() - timedelta(days=1)).isoformat()

    # Construct the full URL for the API endpoint.
    # We are querying the 'subscribed' pulses endpoint.
    url = f"{BASE_URL}/pulses/subscribed?modified_since={since_timestamp}"

    try:
        # Make the GET request to the OTX API.
        response = requests.get(url, headers=headers, timeout=15) # Adding a timeout is good practice.
        # This will raise an exception if the response has a bad status code (like 404 or 500).
        response.raise_for_status()

        # Parse the JSON response from the API.
        data = response.json()
        print(f"Successfully fetched {len(data.get('results', []))} pulses from AlienVault OTX.")
        # The actual pulse data is in the 'results' key of the response.
        return data.get("results", [])

    # --- ROBUST ERROR HANDLING ---
    # It's important to handle different types of potential errors when making API calls.
    except requests.exceptions.HTTPError as http_err:
        print(f"HTTP error occurred: {http_err}")
    except requests.exceptions.ConnectionError as conn_err:
        print(f"Connection error occurred: {conn_err}")
    except requests.exceptions.Timeout as timeout_err:
        print(f"Timeout error occurred: {timeout_err}")
    except requests.exceptions.RequestException as req_err:
        print(f"An unexpected error occurred: {req_err}")
    except json.JSONDecodeError:
        print("Failed to decode JSON from response. The API might be down or returning invalid data.")

    # Return an empty list if any error occurred.
    return []

# --- STANDALONE EXECUTION FOR TESTING ---
if __name__ == "__main__":
    # This block allows the script to be run directly for testing purposes.
    # For example, you can run 'python autoti/collection/otx_collector.py' from the root directory.
    print("--- Testing OTX Data Collector ---")
    latest_pulses = get_latest_pulses(OTX_API_KEY)

    if latest_pulses:
        print(f"\nSuccessfully fetched {len(latest_pulses)} pulses.")
        # Print details of the first 2 pulses for a quick review.
        for pulse in latest_pulses[:2]:
            print("\n--- Sample Pulse ---")
            print(f"  Name: {pulse.get('name')}")
            print(f"  Created: {pulse.get('created')}")
            print(f"  Description: {pulse.get('description', 'No description available.')[:100]}...")
            print(f"  IOC Count: {len(pulse.get('indicators', []))}")
    else:
        print("\nNo pulses fetched. Please check your API key and network connection.")
# This script is responsible for cleaning and structuring the raw data collected from OTX.
# Data normalization is a critical step to ensure the data is consistent and easy to work with
# in the analysis phase. We use the pandas library for efficient data manipulation.

import pandas as pd

def normalize_pulses(raw_pulses):
    """
    Normalizes a list of raw threat intelligence pulses into a structured pandas DataFrame.

    The process involves:
    - Selecting relevant columns.
    - Renaming columns for clarity.
    - Handling missing data.
    - Converting data types.
    - Extracting and creating new, useful features (like IOC count).

    Args:
        raw_pulses (list): A list of dictionaries, where each is a raw pulse from OTX.

    Returns:
        pandas.DataFrame: A clean, structured DataFrame. Returns an empty DataFrame on failure.
    """
    if not raw_pulses:
        print("Input pulse list is empty. Returning an empty DataFrame.")
        return pd.DataFrame()

    # Convert the list of dictionaries into a pandas DataFrame for easier processing.
    df = pd.DataFrame(raw_pulses)

    # --- Data Cleaning and Structuring ---

    # 1. Select Relevant Columns
    # We choose the columns that are most useful for our analysis.
    required_columns = ['id', 'name', 'description', 'created', 'indicators']

    # We filter for columns that actually exist in the DataFrame to avoid errors
    # if the API response changes.
    existing_columns = [col for col in required_columns if col in df.columns]
    df_normalized = df[existing_columns].copy()

    # 2. Rename Columns
    # We use more descriptive and consistent column names.
    rename_map = {
        'id': 'pulse_id',
        'name': 'threat_name',
        'description': 'threat_description',
        'created': 'creation_date'
    }
    df_normalized.rename(columns=rename_map, inplace=True)

    # 3. Handle Missing Values
    # We replace any empty 'description' fields with a standard placeholder.
    df_normalized['threat_description'].fillna('No description provided.', inplace=True)

    # 4. Convert Data Types
    # The 'created' field is a string, but it's more useful as a datetime object
    # for any time-based analysis.
    df_normalized['creation_date'] = pd.to_datetime(df_normalized['creation_date'])

    # 5. Feature Engineering: Extract and Count IOCs
    # We create a new column, 'ioc_count', to store the number of Indicators of Compromise
    # for each threat pulse. This is a useful metric for assessing the pulse's scope.
    if 'indicators' in df_normalized.columns:
        df_normalized['ioc_count'] = df_normalized['indicators'].apply(lambda ioc_list: len(ioc_list) if isinstance(ioc_list, list) else 0)
    else:
        df_normalized['ioc_count'] = 0

    print("Data normalization complete.")
    return df_normalized

# --- STANDALONE EXECUTION FOR TESTING ---
if __name__ == "__main__":
    # This block allows the script to be run directly for testing.
    # We use sample data that mimics the structure of the real API response.
    print("--- Testing Data Normalizer with Sample Data ---")

    sample_raw_data = [
        {
            "id": "668ba07c0823521f753c8c87",
            "name": "Malicious IPs related to Phishing Campaign",
            "description": "A new set of IPs hosting phishing sites targeting financial institutions.",
            "created": "2025-11-03T10:00:00.000Z",
            "indicators": [
                {"type": "IPv4", "indicator": "198.51.100.1"},
                {"type": "IPv4", "indicator": "198.51.100.2"}
            ]
        },
        {
            "id": "668ba07c0823521f753c8c88",
            "name": "Fake Browser Update (SocGholish)",
            "description": "", # Simulate a missing description.
            "created": "2025-11-03T11:30:00.000Z",
            "indicators": [
                {"type": "URL", "indicator": "http://evil-site.com/update.js"}
            ]
        }
    ]

    normalized_df = normalize_pulses(sample_raw_data)

    # Print the resulting DataFrame to verify the normalization process.
    print("\n--- Normalized DataFrame ---")
    print(normalized_df.head())
    print("\n--- DataFrame Info ---")
    # .info() gives a useful summary of the DataFrame's structure and data types.
    normalized_df.info()
